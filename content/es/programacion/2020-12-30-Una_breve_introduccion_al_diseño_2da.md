---
title: "Cap√≠tulo 2: Una breve introducci√≥n al dise√±o de investigaci√≥n (2da parte)"
date: 2020-12-30T18:19:17-08:00
publishdate: 2020-12-31T18:26:17-08:00
description: "(...continuaci√≥n) En este cap√≠tulo, comenzaremos a pensar en las ideas b√°sicas que se necesitan para dise√±ar un estudio, recopilar datos, verificar si la recopilaci√≥n de datos funciona, etc."
#output: 
#   html_document:
#    toc: true # table of content true
draft: false
hideToc: false
enableToc: true
enableTocContent: true
author: Helio
authorEmoji: üëΩ
pinned: false
fig_caption: true
tags:
- R
- Estad√≠stica
series:
- RMarkdown
- Aprendiendo estad√≠stica con R
categories:
- Programaci√≥n
image: images/learning/cap_02.png
---

{{< featuredImage >}} 

---

<style>
body {
text-align: justify}
</style>

<a id="id-01"> </a>

## Evaluar la validez de un estudio
 
M√°s que cualquier otra cosa, un cient√≠fico quiere que su investigaci√≥n sea "v√°lida". La idea conceptual detr√°s de la validez es muy simple: ¬øpuedes confiar en los resultados de tu estudio? De lo contrario, el estudio no es v√°lido. Sin embargo, si bien es f√°cil de establecer, en la pr√°ctica es mucho m√°s dif√≠cil verificar la validez que verificar la confiabilidad. Y con toda honestidad, no hay una noci√≥n precisa y claramente acordada de lo que realmente es la validez. De hecho, hay muchos tipos diferentes de validez, cada uno de los cuales plantea sus propios problemas, y no todas las formas de validez son relevantes para todos los estudios. Voy a hablar de cinco tipos diferentes:

{{< boxmd >}}

- Validez interna
- Validez externa
- Construir validez
- Validez aparente
- Validez ecol√≥gica

{{< /boxmd >}}

Para darle una gu√≠a r√°pida sobre lo que importa aqu√≠ ... (1) La validez interna y externa son las m√°s importantes, ya que se relacionan directamente con la pregunta fundamental de si su estudio realmente funciona. (2) La validez de constructo pregunta si est√°s midiendo lo que crees que eres. (3) La validez aparente no es muy importante excepto en la medida en que te preocupas por las "apariencias". (4) La validez ecol√≥gica es un caso especial de validez aparente que corresponde a un tipo de apariencia que puede interesarle mucho.
 
### Validez interna
 
La validez interna se refiere a la medida en que puede sacar las conclusiones correctas sobre las relaciones causales entre las variables. Se llama "interno" porque se refiere a las relaciones entre las cosas "dentro" del estudio. Ilustremos el concepto con un ejemplo sencillo. Suponga que est√° interesado en saber si una educaci√≥n universitaria le ayuda a escribir mejor. Para hacerlo, re√∫ne a un grupo de estudiantes de primer a√±o, p√≠dales que escriban un ensayo de 1000 palabras y cuente el n√∫mero de errores ortogr√°ficos y gramaticales que cometen. Luego encuentras algunos estudiantes de tercer a√±o, que obviamente han tenido m√°s educaci√≥n universitaria que los de primer a√±o, y repites el ejercicio. Y supongamos que resulta que los alumnos de tercer a√±o producen menos errores. Y entonces concluye que una educaci√≥n universitaria mejora las habilidades de escritura. ¬øCorrecto? Excepto ... el gran problema que tienes con este experimento es que los estudiantes de tercer a√±o son mayores y han tenido m√°s experiencia escribiendo cosas. As√≠ que es dif√≠cil saber con certeza cu√°l es la relaci√≥n causal: ¬øLas personas mayores escriben mejor? ¬øO personas que han tenido m√°s experiencia en la escritura? ¬øO personas que han tenido m√°s educaci√≥n? ¬øCu√°l de las anteriores es la verdadera causa del desempe√±o superior de los de tercer a√±o? ¬øA√±os? ¬øExperiencia? ¬øEducaci√≥n? No se puede decir. Este es un ejemplo de una falla en la validez interna, porque su estudio no separa adecuadamente las relaciones causales entre las diferentes variables.
 
### Validez externa
 
La validez externa se relaciona con la posibilidad de generalizar sus hallazgos. Es decir, en qu√© medida espera ver el mismo patr√≥n de resultados en la "vida real" que vio en su estudio. Para decirlo con un poco m√°s de precisi√≥n, cualquier estudio que hagas en psicolog√≠a involucrar√° un conjunto bastante espec√≠fico de preguntas o tareas, ocurrir√° en un entorno espec√≠fico e involucrar√° a participantes que provienen de un subgrupo particular. Entonces, si resulta que los resultados en realidad no se generalizan a personas y situaciones m√°s all√° de las que estudi√≥, entonces lo que tiene es una falta de validez externa.
 
El ejemplo cl√°sico de este problema es el hecho de que una gran proporci√≥n de los estudios de psicolog√≠a utilizar√°n estudiantes de licenciatura en psicolog√≠a como participantes. Sin embargo, es obvio que a los investigadores no solo les preocupan los estudiantes de psicolog√≠a; se preocupan por la gente en general. Dado eso, un estudio que utiliza solo estudiantes de psiquiatr√≠a como participantes siempre conlleva el riesgo de carecer de validez externa. Es decir, si hay algo ‚Äúespecial‚Äù en los estudiantes de psicolog√≠a que los hace diferentes de la poblaci√≥n en general en alg√∫n aspecto relevante, entonces podemos empezar a preocuparnos por la falta de validez externa.
 
Dicho esto, es absolutamente fundamental darse cuenta de que un estudio que utiliza solo a estudiantes de psicolog√≠a no necesariamente tiene un problema de validez externa. Hablar√© de esto nuevamente m√°s tarde, pero es un error tan com√∫n que lo mencionar√© aqu√≠. La validez externa se ve amenazada por la elecci√≥n de la poblaci√≥n si (a) la poblaci√≥n de la que muestre√≥ a sus participantes es muy limitada (por ejemplo, estudiantes de psicolog√≠a) y (b) la poblaci√≥n restringida de la que tom√≥ la muestra es sistem√°ticamente diferente de la poblaci√≥n general , en alg√∫n aspecto que sea relevante para el fen√≥meno psicol√≥gico que pretende estudiar. La parte en cursiva es la parte que mucha gente olvida: es cierto que los estudiantes de psicolog√≠a se diferencian de la poblaci√≥n en general en muchos aspectos, por lo que un estudio que solo utilice estudiantes de psicolog√≠a puede tener problemas con la validez externa. Sin embargo, si esas diferencias no son muy relevantes para el fen√≥meno que est√° estudiando, entonces no hay nada de qu√© preocuparse. Para hacer esto un poco m√°s concreto, aqu√≠ hay dos ejemplos extremos:

{{< boxmd >}}

- Quiere medir las ‚Äúactitudes del p√∫blico en general hacia la psicoterapia‚Äù, pero todos sus participantes son estudiantes de psicolog√≠a. Es casi seguro que este estudio tenga un problema de validez externa.
- Quiere medir la efectividad de una ilusi√≥n visual y sus participantes son todos estudiantes de psicolog√≠a. Es muy poco probable que este estudio tenga un problema de validez externa.

{{< /boxmd >}}

Habiendo dedicado los √∫ltimos dos p√°rrafos a centrarse en la elecci√≥n de los participantes (ya que ese es el gran problema del que todos tienden a preocuparse m√°s), vale la pena recordar que la validez externa es un concepto m√°s amplio. Los siguientes tambi√©n son ejemplos de cosas que podr√≠an representar una amenaza para la validez externa, seg√∫n el tipo de estudio que est√© realizando:
 
Las personas pueden responder un "cuestionario de psicolog√≠a" de una manera que no refleja lo que har√≠an en la vida real.
{{< boxmd >}} 
- Su experimento de laboratorio sobre (digamos) ‚Äúaprendizaje humano‚Äù tiene una estructura diferente a los problemas de aprendizaje que enfrentan las personas en la vida real.
{{< /boxmd >}}

### Construir validez
 
La validez de constructo es b√°sicamente una cuesti√≥n de si est√°s midiendo lo que quieres medir. Una medici√≥n tiene una buena validez de constructo si en realidad mide el constructo te√≥rico correcto y una mala validez de constructo si no lo hace. Para dar un ejemplo muy simple (aunque rid√≠culo), suponga que estoy tratando de investigar las tasas con las que los estudiantes universitarios hacen trampa en sus ex√°menes. Y la forma en que intento medirlo es pidiendo a los estudiantes que hacen trampa que se pongan de pie en la sala de conferencias para poder contarlos. Cuando hago esto con una clase de 300 estudiantes, 0 personas dicen ser tramposos. Por tanto, llego a la conclusi√≥n de que la proporci√≥n de tramposos en mi clase es del 0%. Claramente esto es un poco rid√≠culo. Pero el punto aqu√≠ no es que este sea un ejemplo metodol√≥gico muy profundo, sino m√°s bien para explicar qu√© es la validez de constructo. El problema con mi medida es que mientras intento medir "la proporci√≥n de personas que enga√±an", lo que en realidad estoy midiendo es "la proporci√≥n de personas lo suficientemente est√∫pidas como para admitir haber hecho trampas, o lo suficientemente sangrientas hacer". ¬°Obviamente, estos no son lo mismo! As√≠ que mi estudio sali√≥ mal, porque mi medici√≥n tiene una validez de constructo muy pobre.
 
### Validez aparente
 
La validez aparente simplemente se refiere a si una medida "parece" que est√° haciendo lo que se supone que debe hacer, nada m√°s. Si dise√±o una prueba de inteligencia, y la gente la mira y dice ‚Äúno, esa prueba no mide la inteligencia‚Äù, entonces la medida carece de validez aparente. Es tan simple como eso. Obviamente, la validez aparente no es muy importante desde una perspectiva cient√≠fica pura. Despu√©s de todo, lo que nos importa es si la medida realmente hace lo que se supone que debe hacer, no si parece que hace lo que se supone que debe hacer. Como consecuencia, generalmente no nos importa mucho la validez aparente. Dicho esto, el concepto de validez aparente tiene tres √∫tiles prop√≥sitos pragm√°ticos:
 
- A veces, un cient√≠fico experimentado tendr√° el "presentimiento" de que una medida en particular no funcionar√°. Si bien este tipo de corazonadas no tienen un valor probatorio estricto, a menudo vale la pena prestarles atenci√≥n. Porque muchas veces las personas tienen un conocimiento que no pueden verbalizar del todo, por lo que puede haber algo de qu√© preocuparse incluso si no puede decir por qu√©. En otras palabras, cuando alguien en quien conf√≠a critica la validez aparente de su estudio, vale la pena tomarse el tiempo para pensar m√°s detenidamente sobre su dise√±o para ver si puede pensar en las razones por las que podr√≠a salir mal. Eso s√≠, si no encuentra ning√∫n motivo de preocupaci√≥n, probablemente no deber√≠a preocuparse: despu√©s de todo, la validez aparente realmente no importa mucho.
 
- A menudo (muy a menudo), las personas completamente desinformadas tambi√©n tendr√°n la "corazonada" de que su investigaci√≥n es una mierda. Y lo criticar√°n en Internet o algo as√≠. En una inspecci√≥n m√°s cercana, a menudo notar√° que estas cr√≠ticas en realidad se centran por completo en c√≥mo "se ve" el estudio, pero no en nada m√°s profundo. El concepto de validez aparente es √∫til para explicar suavemente a las personas que necesitan fundamentar m√°s sus argumentos.
 
- Ampliando el √∫ltimo punto, si las creencias de personas no capacitadas son cr√≠ticas (por ejemplo, este suele ser el caso de la investigaci√≥n aplicada en la que realmente desea convencer a los responsables de la formulaci√≥n de pol√≠ticas de algo u otro), debe preocuparse por la validez aparente. Simplemente porque, te guste o no, mucha gente usar√° la validez aparente como un sustituto de la validez real. Si quiere que el gobierno cambie una ley sobre bases cient√≠ficas y psicol√≥gicas, entonces no importar√° cu√°n buenos sean sus estudios "realmente". Si carecen de validez aparente, descubrir√°s que los pol√≠ticos te ignoran. Por supuesto, es algo injusto que la pol√≠tica a menudo dependa m√°s de la apariencia que de los hechos, pero as√≠ es como van las cosas.
 
### Validez ecol√≥gica
 
La validez ecol√≥gica es una noci√≥n diferente de validez, que es similar a la validez externa, pero menos importante. La idea es que, para que sea ecol√≥gicamente v√°lido, toda la estructura del estudio debe aproximarse mucho al escenario del mundo real que se est√° investigando. En cierto sentido, la validez ecol√≥gica es una especie de validez aparente: se relaciona principalmente con si el estudio "parece" correcto, pero con un poco m√°s de rigor. Para ser ecol√≥gicamente v√°lido, el estudio debe verse bien de una manera bastante espec√≠fica. La idea detr√°s de esto es la intuici√≥n de que un estudio que es ecol√≥gicamente v√°lido tiene m√°s probabilidades de ser v√°lido externamente. No es garant√≠a, por supuesto. Pero lo bueno de la validez ecol√≥gica es que es mucho m√°s f√°cil comprobar si un estudio es ecol√≥gicamente v√°lido que comprobar si un estudio es v√°lido externamente. Un ejemplo simple ser√≠an los estudios de identificaci√≥n de testigos presenciales. La mayor√≠a de estos estudios tienden a realizarse en un entorno universitario, a menudo con una variedad bastante simple de rostros para mirar en lugar de una fila. El per√≠odo de tiempo entre ver al "criminal" y que se le pide que identifique al sospechoso en la "fila" suele ser m√°s corto. El "crimen" no es real, por lo que no hay posibilidad de que el testigo est√© asustado y no haya agentes de polic√≠a presentes, por lo que no hay tantas posibilidades de sentirse presionado. Todas estas cosas significan que el estudio definitivamente carece de validez ecol√≥gica. Pueden significar (pero no) que tambi√©n carece de validez externa.


<p style="text-align:right;">
<a href="#id-01">Volver</a>
</p>

---

## Confusiones, artefactos y otras amenazas a la validez
 
Si miramos el tema de la validez de la manera m√°s general, las dos mayores preocupaciones que tenemos son las confusiones y los artefactos. Estos dos t√©rminos se definen de la siguiente manera:
 
- Confusi√≥n: Una confusi√≥n es una variable 5 adicional, a menudo no medida, que resulta estar relacionada tanto con los predictores como con los resultados. La existencia de factores de confusi√≥n amenaza la validez interna del estudio porque no se puede decir si el predictor causa el resultado o si la variable de confusi√≥n lo causa, etc.
 
- Artefacto: se dice que un resultado es ‚Äúartefacto‚Äù si solo se cumple en la situaci√≥n especial que usted prob√≥ en su estudio. La posibilidad de que su resultado sea un artefacto describe una amenaza a su validez externa, porque plantea la posibilidad de que no pueda generalizar sus resultados a la poblaci√≥n real que le interesa.
 
Como regla general, las confusiones son una preocupaci√≥n mayor para los estudios no experimentales, precisamente porque no son experimentos adecuados: por definici√≥n, est√°s dejando muchas cosas sin controlar, por lo que hay mucho margen para que las confusiones se abran paso en tu estudio. . La investigaci√≥n experimental tiende a ser mucho menos vulnerable a las confusiones: cuanto m√°s control tenga sobre lo que sucede durante el estudio, m√°s podr√° evitar que aparezcan confusiones.
 
Sin embargo, siempre hay columpios y rotondas, y cuando empezamos a pensar en artefactos en lugar de confusiones, el zapato est√° muy firmemente en el otro pie. En su mayor parte, los resultados de artefactos tienden a ser una preocupaci√≥n para los estudios experimentales que para los estudios no experimentales. Para ver esto, es √∫til darse cuenta de que la raz√≥n por la que muchos estudios no son experimentales es precisamente porque lo que el investigador est√° tratando de hacer es examinar el comportamiento humano en un contexto m√°s naturalista. Al trabajar en un contexto m√°s del mundo real, pierde el control experimental (haci√©ndose vulnerable a las confusiones), pero debido a que tiende a estudiar psicolog√≠a humana "en la naturaleza", reduce las posibilidades de obtener un resultado artificial. O, para decirlo de otra manera, cuando sacas la psicolog√≠a de la naturaleza y la llevas al laboratorio (lo que generalmente tenemos que hacer para ganar nuestro control experimental), siempre corres el riesgo de estudiar accidentalmente algo diferente de lo que quer√≠as. estudio: que es m√°s o menos la definici√≥n de un artefacto. Sin embargo, tenga cuidado: lo anterior es solo una gu√≠a aproximada. Es absolutamente posible tener confusiones en un experimento y obtener resultados artificiales con estudios no experimentales. Esto puede suceder por todo tipo de razones, entre las que se encuentra el error del investigador. En la pr√°ctica, es muy dif√≠cil pensar en todo con anticipaci√≥n, e incluso los investigadores muy buenos cometen errores. Pero otras veces es inevitable, simplemente porque el investigador tiene √©tica (por ejemplo, ver "desgaste diferencial").
 
Bueno. Hay un sentido en el que casi cualquier amenaza a la validez puede caracterizarse como una confusi√≥n o un artefacto: son conceptos bastante vagos. As√≠ que echemos un vistazo a algunos de los ejemplos m√°s comunes ...
 
### Efectos de la historia
 
Los efectos del historial se refieren a la posibilidad de que ocurran eventos espec√≠ficos durante el estudio mismo que podr√≠an influir en los resultados. Por ejemplo, podr√≠a suceder algo entre una prueba previa y una prueba posterior. O, entre probar al participante 23 y al participante 24. Alternativamente, podr√≠a ser que est√© viendo un estudio m√°s antiguo, que era perfectamente v√°lido para su √©poca, pero el mundo ha cambiado lo suficiente desde entonces que las conclusiones ya no son confiables. Ejemplos de cosas que contar√≠an como efectos hist√≥ricos:
 
- Le interesa c√≥mo piensa la gente sobre el riesgo y la incertidumbre. Comenz√≥ su recopilaci√≥n de datos en diciembre de 2010. Pero encontrar participantes y recopilar datos lleva tiempo, por lo que todav√≠a est√° encontrando gente nueva en febrero de 2011. Desafortunadamente para usted (y m√°s desafortunadamente para otros), las inundaciones de Queensland ocurrieron en enero de 2011, causando miles de millones de d√≥lares en da√±os y matando a muchas personas. No es sorprendente que las personas evaluadas en febrero de 2011 expresen creencias bastante diferentes sobre el manejo del riesgo que las personas evaluadas en diciembre de 2010. ¬øCu√°l (si alguna) de √©stas refleja las creencias ‚Äúverdaderas‚Äù de los participantes? Creo que la respuesta es probablemente ambas: las inundaciones de Queensland cambiaron genuinamente las creencias del p√∫blico australiano, aunque posiblemente solo temporalmente. La clave aqu√≠ es que la ‚Äúhistoria‚Äù de las personas probadas en febrero es bastante diferente a la de las personas probadas en diciembre.
 
- Est√° probando los efectos psicol√≥gicos de un nuevo medicamento contra la ansiedad. Entonces, lo que se hace es medir la ansiedad antes de administrar el f√°rmaco (por ejemplo, mediante un autoinforme y tomando medidas fisiol√≥gicas, digamos), luego se administra el f√°rmaco y luego se toman las mismas medidas. En el medio, sin embargo, debido a que sus laboratorios est√°n en Los √Ångeles, hay un terremoto que aumenta la ansiedad de los participantes.
 
### Efectos de maduraci√≥n
 
Como ocurre con los efectos de la historia, los efectos de maduraci√≥n tienen que ver fundamentalmente con el cambio en el tiempo. Sin embargo, los efectos de la maduraci√≥n no responden a eventos espec√≠ficos. M√°s bien, se relacionan con c√≥mo las personas cambian por s√≠ mismas con el tiempo: envejecemos, nos cansamos, nos aburrimos, etc. Algunos ejemplos de efectos de maduraci√≥n:
 
- Al realizar una investigaci√≥n en psicolog√≠a del desarrollo, debe tener en cuenta que los ni√±os crecen con bastante rapidez. Entonces, suponga que desea averiguar si alg√∫n truco educativo ayuda con el tama√±o del vocabulario entre los ni√±os de 3 a√±os. Una cosa que debe tener en cuenta es que el tama√±o del vocabulario de los ni√±os de esa edad est√° creciendo a un ritmo incre√≠ble (varias palabras por d√≠a), por s√≠ solo. Si dise√±a su estudio sin tener en cuenta este efecto de maduraci√≥n, no podr√° saber si su truco educativo funciona.
 
- Cuando se realiza un experimento muy largo en el laboratorio (digamos, algo que dura 3 horas), es muy probable que las personas comiencen a aburrirse y a cansarse, y que este efecto de maduraci√≥n haga que el rendimiento disminuya, independientemente de lo que suceda. en el experimento
 
### Efectos de prueba repetidos
 
Un tipo importante de efecto hist√≥rico es el efecto de las pruebas repetidas. Supongamos que quiero tomar dos medidas de alg√∫n constructo psicol√≥gico (por ejemplo, ansiedad). Una cosa que podr√≠a preocuparme es si la primera medici√≥n tiene un efecto sobre la segunda medici√≥n. En otras palabras, se trata de un efecto hist√≥rico en el que el "evento" que influye en la segunda medici√≥n es la primera medici√≥n en s√≠. Esto no es nada raro. Ejemplos de esto incluyen:
 
- Aprendizaje y pr√°ctica: por ejemplo, la ‚Äúinteligencia‚Äù en el tiempo 2 puede parecer que aumenta en relaci√≥n con el tiempo 1 porque los participantes aprendieron las reglas generales de c√≥mo resolver preguntas de ‚Äúestilo de prueba de inteligencia‚Äù durante la primera sesi√≥n de prueba.
 
- Familiaridad con la situaci√≥n de la prueba: por ejemplo, si las personas est√°n nerviosas en el momento 1, esto podr√≠a hacer que el rendimiento disminuya; Despu√©s de pasar por la primera situaci√≥n de prueba, es posible que se calmen mucho precisamente porque han visto c√≥mo se ve la prueba.
 
- Cambios auxiliares causados por las pruebas: por ejemplo, si un cuestionario que eval√∫a el estado de √°nimo es aburrido, entonces es m√°s probable que el estado de √°nimo en la medici√≥n en el momento 2 se "aburra", precisamente debido a la medici√≥n aburrida realizada en el momento 1.
 
### Sesgo de selecci√≥n
 
El sesgo de selecci√≥n es un t√©rmino bastante amplio. Suponga que est√° ejecutando un experimento con dos grupos de participantes, donde cada grupo recibe un "tratamiento" diferente, y desea ver si los diferentes tratamientos conducen a diferentes resultados. Sin embargo, suponga que, a pesar de sus mejores esfuerzos, ha terminado con un desequilibrio de g√©nero entre los grupos (digamos, el grupo A tiene un 80% de mujeres y el grupo B un 50% de mujeres). Puede parecer que esto nunca podr√≠a suceder, pero cr√©ame, puede. Este es un ejemplo de un sesgo de selecci√≥n, en el que las personas "seleccionadas" en los dos grupos tienen caracter√≠sticas diferentes. Si alguna de esas caracter√≠sticas resulta ser relevante (digamos, su tratamiento funciona mejor en mujeres que en hombres), entonces est√° en un gran problema.
 
### Desgaste diferencial
 
Un peligro bastante sutil a tener en cuenta se llama desgaste diferencial, que es una especie de sesgo de selecci√≥n causado por el estudio en s√≠. Supongamos que, por primera vez en la historia de la psicolog√≠a, logro encontrar la muestra de personas perfectamente equilibrada y representativa. Empiezo a ejecutar el ‚Äúexperimento incre√≠blemente largo y tedioso de Dan‚Äù en mi muestra perfecta, pero luego, debido a que mi estudio es incre√≠blemente largo y tedioso, mucha gente comienza a abandonar. No puedo detener esto: como discutiremos m√°s adelante en el cap√≠tulo sobre √©tica de la investigaci√≥n, los participantes tienen absolutamente el derecho de dejar de hacer cualquier experimento, en cualquier momento, por la raz√≥n que quieran, y como investigadores somos moral (y profesionalmente) ) obligada a recordar a las personas que tienen este derecho. Por lo tanto, suponga que "el experimento incre√≠blemente largo y tedioso de Dan" tiene una tasa de abandono muy alta. ¬øCu√°les cree que son las probabilidades de que esta deserci√≥n sea aleatoria? Respuesta: cero. Es casi seguro que las personas que se quedan son m√°s conscientes, m√°s tolerantes con el aburrimiento, etc. que las que se van. En la medida en que (digamos) la conciencia es relevante para el fen√≥meno psicol√≥gico que me importa, este desgaste puede disminuir la validez de mis resultados.
 
Al pensar en los efectos de la deserci√≥n diferencial, a veces es √∫til distinguir entre dos tipos diferentes. El primero es el desgaste homog√©neo, en el que el efecto de desgaste es el mismo para todos los grupos, tratamientos o condiciones. En el ejemplo que di anteriormente, la deserci√≥n diferencial ser√≠a homog√©nea si (y solo si) los participantes que se aburren f√°cilmente abandonan todas las condiciones de mi experimento aproximadamente al mismo ritmo. En general, es probable que el efecto principal de la deserci√≥n homog√©nea sea que haga que su muestra no sea representativa. Como tal, la mayor preocupaci√≥n que tendr√° es que la generalizabilidad de los resultados disminuya: en otras palabras, pierde validez externa.
 
El segundo tipo de deserci√≥n diferencial es la deserci√≥n heterog√©nea, en la que el efecto de deserci√≥n es diferente para diferentes grupos. Este es un problema mucho mayor: no solo tienes que preocuparte por tu validez externa, tambi√©n tienes que preocuparte por tu validez interna. Para ver por qu√© este es el caso, consideremos un estudio muy tonto en el que quiero ver si insultar a las personas las hace actuar de una manera m√°s obediente. No s√© por qu√© alguien querr√≠a estudiar en realidad, pero supongamos que esto realmente me importaba profundamente. Entonces, dise√±o mi experimento con dos condiciones. En la condici√≥n de "tratamiento", el experimentador insulta al participante y luego le da un cuestionario dise√±ado para medir la obediencia. En la condici√≥n de "control", el experimentador se involucra en una peque√±a charla in√∫til y luego les da el cuestionario. Dejando de lado los m√©ritos cient√≠ficos cuestionables y la √©tica dudosa de tal estudio, pensemos en lo que podr√≠a salir mal aqu√≠. Como regla general, cuando alguien me insulta en la cara, tiendo a ser mucho menos cooperativo. Por lo tanto, es muy probable que muchas m√°s personas abandonen la condici√≥n de tratamiento que la condici√≥n de control. Y esta deserci√≥n no ser√° aleatoria. Las personas m√°s propensas a abandonar probablemente ser√≠an las personas a las que no les importa demasiado la importancia de sentarse obedientemente durante el experimento. Dado que las personas m√°s sangrientas y desobedientes abandonaron el grupo de tratamiento, pero no el grupo de control, hemos introducido una confusi√≥n: las personas que realmente respondieron el cuestionario en el grupo de tratamiento ya ten√≠an m√°s probabilidades de ser obedientes y obedientes que las personas en el grupo de control. En resumen, en este estudio, insultar a las personas no las hace m√°s obedientes: ¬°hace que las personas m√°s desobedientes abandonen el experimento! La validez interna de este experimento est√° completamente disparada.
 
### Sesgo de no respuesta
 
El sesgo de no respuesta est√° estrechamente relacionado con el sesgo de selecci√≥n y con el desgaste diferencial. La versi√≥n m√°s simple del problema es la siguiente. Env√≠a una encuesta a 1000 personas y solo 300 de ellas responden. Es casi seguro que las 300 personas que respondieron no son una submuestra aleatoria. Las personas que responden a las encuestas son sistem√°ticamente diferentes a las que no lo hacen. Esto introduce un problema al intentar generalizar desde esas 300 personas que respondieron, a la poblaci√≥n en general; ya que ahora tiene una muestra muy no aleatoria. Sin embargo, la cuesti√≥n del sesgo de no respuesta es m√°s general que esto. Entre las (digamos) 300 personas que respondieron la encuesta, es posible que no todos respondan todas las preguntas. Si (digamos) 80 personas optaron por no responder una de sus preguntas, ¬øesto presenta problemas? Como siempre, la respuesta es quiz√°s. Si la pregunta que no fue respondida estaba en la √∫ltima p√°gina del cuestionario, y esas 80 encuestas fueron devueltas sin la √∫ltima p√°gina, es muy probable que los datos faltantes no sean un gran problema: probablemente las p√°ginas simplemente se cayeron . Sin embargo, si la pregunta que no respondieron 80 personas fue la pregunta personal m√°s agresiva o agresiva del cuestionario, es casi seguro que tienes un problema. En esencia, lo que est√° tratando aqu√≠ es lo que se llama el problema de los datos faltantes. Si los datos que faltan se ‚Äúperdieron‚Äù al azar, entonces no es un gran problema. Si falta sistem√°ticamente, puede ser un gran problema.
 
### Regresi√≥n a la media
 
La regresi√≥n a la media es una variaci√≥n curiosa del sesgo de selecci√≥n. Se refiere a cualquier situaci√≥n en la que seleccione datos en funci√≥n de un valor extremo en alguna medida. Debido a que la medida tiene una variaci√≥n natural, es casi seguro que significa que cuando tome una medici√≥n posterior, esa medici√≥n posterior ser√° menos extrema que la primera, por pura casualidad.
 
He aqu√≠ un ejemplo. Supongamos que estoy interesado en saber si una educaci√≥n en psicolog√≠a tiene un efecto adverso en los ni√±os muy inteligentes. Para hacer esto, busco a los 20 estudiantes de Psicolog√≠a I con las mejores calificaciones de la escuela secundaria y observo qu√© tan bien les est√° yendo en la universidad. Resulta que lo est√°n haciendo mucho mejor que el promedio, pero no est√°n encabezando la clase en la universidad, a pesar de que obtuvieron los mejores resultados en la escuela secundaria. ¬øQue esta pasando? El primer pensamiento natural es que esto debe significar que las clases de psicolog√≠a deben tener un efecto adverso en esos estudiantes. Sin embargo, aunque esa podr√≠a ser la explicaci√≥n, es m√°s probable que lo que est√° viendo sea un ejemplo de "regresi√≥n a la media". Para ver c√≥mo funciona, tomemos un momento para pensar en lo que se requiere para obtener la mejor nota en una clase, sin importar si esa clase es en la escuela secundaria o en la universidad. Cuando tengas una clase grande, habr√° mucha gente muy inteligente inscrita. Para obtener la mejor nota hay que ser muy inteligente, trabajar muy duro y tener un poco de suerte. El examen tiene que formular las preguntas adecuadas para sus habilidades idiosincr√°sicas, y no debe cometer ning√∫n error tonto (todos lo hacemos a veces) al responderlas. Y esa es la cuesti√≥n: la inteligencia y el trabajo duro se pueden transferir de una clase a otra. La suerte no lo es. Las personas que tuvieron suerte en la escuela secundaria no ser√°n las mismas que las que tuvieron suerte en la universidad. Esa es la definici√≥n misma de "suerte". La consecuencia de esto es que, cuando selecciona personas en los valores muy extremos de una medici√≥n (los 20 mejores estudiantes), est√° seleccionando por trabajo duro, habilidad y suerte. Pero debido a que la suerte no se transfiere a la segunda medici√≥n (solo la habilidad y el trabajo), se espera que todas estas personas bajen un poco cuando las mida por segunda vez (en la universidad). Entonces sus puntajes retroceden un poco, hacia todos los dem√°s. Esta es una regresi√≥n a la media.
 
La regresi√≥n a la media es sorprendentemente com√∫n. Por ejemplo, si dos personas muy altas tienen hijos, estos tender√°n a ser m√°s altos que el promedio, pero no tan altos como los padres. Lo contrario sucede con los padres muy bajos: dos padres muy bajos tender√°n a tener hijos bajos, pero sin embargo, esos ni√±os tender√°n a ser m√°s altos que los padres. Tambi√©n puede ser extremadamente sutil. Por ejemplo, se han realizado estudios que sugirieron que las personas aprenden mejor de los comentarios negativos que de los positivos. Sin embargo, la forma en que la gente trataba de demostrar esto era darles un refuerzo positivo cuando lo hac√≠an bien y un refuerzo negativo cuando lo hac√≠an mal. Y lo que ves es que despu√©s del refuerzo positivo, la gente tend√≠a a hacerlo peor; pero despu√©s del refuerzo negativo tendieron a hacerlo mejor. ¬°Pero! Observe que hay un sesgo de selecci√≥n aqu√≠: cuando a las personas les va muy bien, est√° seleccionando valores "altos", por lo que debe esperar (debido a la regresi√≥n a la media) que el rendimiento en la siguiente prueba sea peor, independientemente de si se da refuerzo. Del mismo modo, despu√©s de una mala prueba, las personas tender√°n a mejorar por s√≠ mismas. La aparente superioridad de la retroalimentaci√≥n negativa es un artefacto causado por la regresi√≥n a la media (ver Kahneman & Tversky, 1973, para discusi√≥n).
 
### Sesgo del experimentador
 
El sesgo del experimentador puede presentarse de m√∫ltiples formas. La idea b√°sica es que el experimentador, a pesar de las mejores intenciones, puede terminar influyendo accidentalmente en los resultados del experimento al comunicar sutilmente la ‚Äúrespuesta correcta‚Äù o el ‚Äúcomportamiento deseado‚Äù a los participantes. Por lo general, esto ocurre porque el experimentador tiene un conocimiento especial que el participante no tiene, ya sea la respuesta correcta a las preguntas que se formulan o el conocimiento del patr√≥n de desempe√±o esperado para la condici√≥n en la que se encuentra el participante, etc. El ejemplo cl√°sico de esto es el caso de estudio de ‚ÄúClever Hans‚Äù, que se remonta a 1907 (Pfungst, 1911; Hothersall, 2004). Clever Hans era un caballo que aparentemente pod√≠a leer y contar, y realizar otras haza√±as de inteligencia humanas. Despu√©s de que Clever Hans se hizo famoso, los psic√≥logos comenzaron a examinar su comportamiento m√°s de cerca. Result√≥ que, como era de esperar, Hans no sab√≠a c√≥mo hacer matem√°ticas. M√°s bien, Hans estaba respondiendo a los observadores humanos que lo rodeaban. Porque sab√≠an contar y el caballo hab√≠a aprendido a cambiar su comportamiento cuando la gente cambiaba el suyo.
 
La soluci√≥n general al problema del sesgo del experimentador es participar en estudios doble ciego, donde ni el experimentador ni el participante saben en qu√© condici√≥n se encuentra el participante, o saben cu√°l es el comportamiento deseado. Esto proporciona una muy buena soluci√≥n al problema, pero es importante reconocer que no es del todo ideal y es dif√≠cil de lograr a la perfecci√≥n. Por ejemplo, la forma obvia en que podr√≠a intentar construir un estudio doble ciego es tener uno de mis doctores. los estudiantes (uno que no sabe nada sobre el experimento) realizan el estudio. Eso parece que deber√≠a ser suficiente. La √∫nica persona (yo) que conoce todos los detalles (por ejemplo, respuestas correctas a las preguntas, asignaciones de los participantes a las condiciones) no tiene interacci√≥n con los participantes, y la persona que habla con la gente (el estudiante de doctorado) ) no sabe nada. Excepto que es muy poco probable que esa √∫ltima parte sea cierta. Para que el Ph.D. estudiante para ejecutar el estudio de manera eficaz, deben haber sido informados por m√≠, el investigador. Y resulta que el Ph.D. El estudiante tambi√©n me conoce, y sabe un poco sobre mis creencias generales sobre las personas y la psicolog√≠a (por ejemplo, tiendo a pensar que los humanos son mucho m√°s inteligentes de lo que los psic√≥logos creen). Como resultado de todo esto, es casi imposible que el experimentador evite conocer un poco las expectativas que tengo. E incluso un poco de conocimiento puede tener un efecto: supongamos que el experimentador transmite accidentalmente el hecho de que se espera que los participantes lo hagan bien en esta tarea. Bueno, hay algo llamado ‚Äúefecto Pigmali√≥n‚Äù: si esperas grandes cosas de las personas, estar√°n a la altura de las circunstancias; pero si espera que fallen, tambi√©n lo har√°n. En otras palabras, las expectativas se convierten en una profec√≠a autocumplida.
 
### Efectos de demanda y reactividad
 
Cuando se habla de sesgo del experimentador, la preocupaci√≥n es que el conocimiento o los deseos del experimentador para el experimento se comuniquen a los participantes y que estos afecten el comportamiento de las personas (Rosenthal, 1966). Sin embargo, incluso si logra evitar que esto suceda, es casi imposible evitar que las personas sepan que son parte de un estudio psicol√≥gico. Y el mero hecho de saber que alguien te est√° mirando / estudiando puede tener un efecto bastante grande en el comportamiento. Esto se conoce generalmente como efectos de reactividad o demanda. La idea b√°sica es captada por el efecto Hawthorne: las personas alteran su desempe√±o debido a la atenci√≥n que el estudio les presta. El efecto toma su nombre de la f√°brica "Hawthorne Works" en las afueras de Chicago (ver Adair, 1984). Un estudio realizado en la d√©cada de 1920 que analiz√≥ los efectos de la iluminaci√≥n en la productividad de los trabajadores en la f√°brica result√≥ ser un efecto del hecho de que los trabajadores sab√≠an que estaban siendo estudiados, en lugar de la iluminaci√≥n.
 
Para ser un poco m√°s espec√≠fico sobre algunas de las formas en que el mero hecho de participar en un estudio puede cambiar la forma en que se comportan las personas, es √∫til pensar como un psic√≥logo social y observar algunos de los roles que las personas podr√≠an adoptar durante un experimento. pero podr√≠a no adoptar si los eventos correspondientes estuvieran ocurriendo en el mundo real:
 
El buen participante intenta ser demasiado √∫til para el investigador: busca descubrir las hip√≥tesis del experimentador y confirmarlas.
 
- El participante negativo hace exactamente lo contrario del participante bueno: busca romper o destruir el estudio o la hip√≥tesis de alguna manera.
 
- El participante fiel es anormalmente obediente: busca seguir las instrucciones a la perfecci√≥n, independientemente de lo que pueda haber sucedido en un entorno m√°s realista.
 
- El participante aprensivo se pone nervioso por ser examinado o estudiado, tanto que su comportamiento se vuelve altamente antinatural o demasiado deseable socialmente
 
### Efectos placebo
 
El efecto placebo es un tipo espec√≠fico de efecto de demanda que nos preocupa mucho. Se refiere a la situaci√≥n en la que el mero hecho de ser tratado provoca una mejora en los resultados. El ejemplo cl√°sico proviene de los ensayos cl√≠nicos: si le das a las personas un f√°rmaco qu√≠micamente inerte y les dices que es una cura para una enfermedad, tender√°n a mejorar m√°s r√°pido que las personas que no reciben ning√∫n tratamiento. En otras palabras, es la creencia de las personas de que est√°n siendo tratadas lo que mejora los resultados, no el medicamento.
 
### Efectos de situaci√≥n, medici√≥n y subpoblaci√≥n
 
En algunos aspectos, estos t√©rminos son un t√©rmino general para "todas las dem√°s amenazas a la validez externa". Se refieren al hecho de que la elecci√≥n de la subpoblaci√≥n de la que extrae a sus participantes, la ubicaci√≥n, el momento y la forma en que realiza su estudio (incluido qui√©n recopila los datos) y las herramientas que utiliza para realizar sus mediciones pueden estar influyendo Los resultados. Espec√≠ficamente, la preocupaci√≥n es que estas cosas podr√≠an estar influyendo en los resultados de tal manera que los resultados no se generalizar√°n a una gama m√°s amplia de personas, lugares y medidas.
 
### Fraude, enga√±o y autoenga√±o
 
Una √∫ltima cosa que siento que deber√≠a mencionar. Mientras le√≠a lo que los libros de texto a menudo dicen sobre la evaluaci√≥n de la validez del estudio, no pude evitar notar que parecen suponer que el investigador es honesto. Encuentro esto divertido. Si bien la gran mayor√≠a de los cient√≠ficos son honestos, al menos en mi experiencia, algunos no lo son. 6 No solo eso, como mencion√© anteriormente, los cient√≠ficos no son inmunes al sesgo de creencias; es f√°cil que un investigador termine enga√±√°ndose a s√≠ mismo haci√©ndose creer lo incorrecto, y esto puede llevarlo a realizar una investigaci√≥n sutilmente defectuosa y luego ocultar esas fallas. cuando lo escriban. Por lo tanto, debe considerar no solo la posibilidad (probablemente improbable) de un fraude total, sino tambi√©n la posibilidad (probablemente bastante com√∫n) de que la investigaci√≥n sea "sesgada" involuntariamente. Abr√≠ algunos libros de texto est√°ndar y no encontr√© mucha discusi√≥n sobre este problema, as√≠ que aqu√≠ est√° mi propio intento de enumerar algunas formas en las que pueden surgir estos problemas:
 
- Fabricaci√≥n de datos. A veces, las personas simplemente inventan los datos. Esto se hace ocasionalmente con "buenas" intenciones. Por ejemplo, el investigador cree que los datos fabricados reflejan la verdad y, de hecho, pueden reflejar versiones "ligeramente depuradas" de los datos reales. En otras ocasiones, el fraude es deliberado y malicioso. Algunos ejemplos de alto perfil en los que se ha alegado o mostrado la fabricaci√≥n de datos incluyen a Cyril Burt (un psic√≥logo que se cree que ha fabricado algunos de sus datos), Andrew Wakefield (que ha sido acusado de fabricar sus datos que conectan la vacuna MMR con el autismo) y Hwang Woo-suk (quien falsific√≥ muchos de sus datos sobre la investigaci√≥n con c√©lulas madre).
 
- Bromas. Los enga√±os comparten muchas similitudes con la fabricaci√≥n de datos, pero difieren en el prop√≥sito previsto. Un enga√±o es a menudo una broma, y muchos de ellos est√°n destinados a ser (eventualmente) descubiertos. A menudo, el objetivo de un enga√±o es desacreditar a alguien o alg√∫n campo. Hay bastantes enga√±os cient√≠ficos bien conocidos que se han producido a lo largo de los a√±os (por ejemplo, el hombre de Piltdown), algunos de los cuales fueron intentos deliberados de desacreditar campos particulares de investigaci√≥n (por ejemplo, el caso Sokal).
 
- Tergiversaci√≥n de datos. Si bien el fraude ocupa la mayor√≠a de los titulares, en mi experiencia es mucho m√°s com√∫n ver que los datos se tergiversan. Cuando digo esto, no me refiero a que los peri√≥dicos se equivoquen (lo que hacen, casi siempre). Me refiero al hecho de que, a menudo, los datos en realidad no dicen lo que los investigadores creen que dicen. Mi suposici√≥n es que, casi siempre, esto no es el resultado de una deshonestidad deliberada, se debe a una falta de sofisticaci√≥n en los an√°lisis de datos. Por ejemplo, piense en el ejemplo de la paradoja de Simpson que coment√© al principio de estas notas. Es muy com√∫n ver a personas presentar datos "agregados" de alg√∫n tipo; y, a veces, cuando profundiza y encuentra los datos sin procesar, descubre que los datos agregados cuentan una historia diferente a los datos desagregados. Alternativamente, puede encontrar que alg√∫n aspecto de los datos se est√° ocultando, porque cuenta una historia inconveniente (por ejemplo, el investigador podr√≠a optar por no referirse a una variable en particular). Hay muchas variantes en esto; muchos de los cuales son muy dif√≠ciles de detectar.
 
- Estudie "dise√±o incorrecto". De acuerdo, este es sutil. B√°sicamente, el problema aqu√≠ es que un investigador dise√±a un estudio que tiene fallas incorporadas, y esas fallas nunca se informan en el documento. Los datos que se reportan son completamente reales y est√°n correctamente analizados, pero son producidos por un estudio que en realidad est√° muy mal elaborado. El investigador realmente quiere encontrar un efecto en particular, por lo que el estudio est√° configurado de tal manera que sea "f√°cil" observar (de forma artificial) ese efecto. Una forma enga√±osa de hacer esto, en caso de que tenga ganas de incursionar en un poco de fraude, es dise√±ar un experimento en el que sea obvio para los participantes lo que "se supone" que deben hacer, y luego dejar que la reactividad funcione. es magia para ti. Si lo desea, puede agregar todos los adornos de la experimentaci√≥n a doble ciego, etc. No har√° ninguna diferencia, ya que los materiales de estudio en s√≠ le dicen sutilmente a la gente lo que usted quiere que hagan. Cuando escribe los resultados, el fraude no ser√° obvio para el lector: lo que es obvio para el participante cuando est√° en el contexto experimental no siempre es obvio para la persona que lee el art√≠culo. Por supuesto, la forma en que he descrito esto hace que parezca que siempre es un fraude: probablemente hay casos en los que esto se hace deliberadamente, pero en mi experiencia, la mayor preocupaci√≥n ha sido el dise√±o incorrecto no intencional. El investigador cree ... y entonces el estudio acaba con un defecto incorporado, y ese defecto se borra m√°gicamente cuando el estudio se redacta para su publicaci√≥n.
 
- Miner√≠a de datos e hip√≥tesis post hoc. Otra forma en que los autores de un estudio pueden mentir m√°s o menos sobre lo que encontraron es participando en lo que se conoce como ‚Äúminer√≠a de datos‚Äù. Como discutiremos m√°s adelante en la clase, si sigues intentando analizar tus datos de muchas formas diferentes, eventualmente encontrar√°s algo que ‚Äúparece‚Äù un efecto real pero no lo es. Esto se conoce como "miner√≠a de datos". Sol√≠a ser bastante raro porque el an√°lisis de datos sol√≠a llevar semanas, pero ahora que todos tienen un software estad√≠stico muy poderoso en sus computadoras, se est√° volviendo muy com√∫n. La miner√≠a de datos en s√≠ no es "incorrecta", pero cuanto m√°s lo hace, mayor es el riesgo que corre. Lo que est√° mal, y sospecho que es muy com√∫n, es la miner√≠a de datos no reconocida. Es decir, el investigador realiza todos los an√°lisis posibles conocidos por la humanidad, encuentra el que funciona y luego finge que este fue el √∫nico an√°lisis que realiz√≥. Peor a√∫n, a menudo "inventan" una hip√≥tesis despu√©s de mirar los datos, para encubrir la miner√≠a de datos. Para ser claros: no est√° mal cambiar sus creencias despu√©s de mirar los datos y volver a analizar sus datos utilizando sus nuevas hip√≥tesis "post hoc". Lo que est√° mal (y sospecho que es com√∫n) es no reconocer que lo ha hecho. Si reconoce que lo hizo, otros investigadores pueden tener en cuenta su comportamiento. Si no lo hace, no pueden. Y eso hace que su comportamiento sea enga√±oso. ¬°Malo!
 
- Sesgo de publicaci√≥n y autocensura. Por √∫ltimo, un sesgo generalizado es "no informar" de los resultados negativos. Esto es casi imposible de prevenir. Las revistas no publican todos los art√≠culos que se les env√≠an: prefieren publicar art√≠culos que encuentran ‚Äúalgo‚Äù. Entonces, si 20 personas realizan un experimento para ver si leer Finnegans Wake causa locura en los humanos, y 19 de ellos descubren que no es as√≠, ¬øcu√°l crees que se publicar√°? Obviamente, es el √∫nico estudio que encontr√≥ que Finnegans Wake causa locura 7. Este es un ejemplo de sesgo de publicaci√≥n: dado que nadie public√≥ los 19 estudios que no encontraron un efecto, un lector ingenuo nunca sabr√≠a que existieron. Peor a√∫n, la mayor√≠a de los investigadores "internalizan" este sesgo y terminan autocensurando su investigaci√≥n. Sabiendo que los resultados negativos no ser√°n aceptados para su publicaci√≥n, ni siquiera intentan informarlos. Como dice un amigo m√≠o, ‚Äúpor cada experimento que publicas, tambi√©n tienes 10 fracasos‚Äù. Y ella tiene raz√≥n. El problema es que, si bien algunos (tal vez la mayor√≠a) de esos estudios fracasan por razones aburridas (por ejemplo, usted se emborrach√≥), otros podr√≠an ser resultados genuinos "nulos" que debe reconocer cuando escribe el experimento "bueno". Y decir cu√°l es cu√°l es a menudo dif√≠cil de hacer. Un buen lugar para comenzar es un art√≠culo de Ioannidis (2005) con el deprimente t√≠tulo ‚ÄúPor qu√© la mayor√≠a de los hallazgos de investigaci√≥n publicados son falsos‚Äù. Tambi√©n sugiero echar un vistazo al trabajo de K√ºhberger, Fritz y Scherndl (2014) que presenta evidencia estad√≠stica de que esto realmente sucede en psicolog√≠a.
 
Probablemente haya muchos m√°s temas como este en los que pensar, pero eso servir√° para empezar. Lo que realmente quiero se√±alar es la verdad deslumbrantemente obvia de que la ciencia del mundo real est√° dirigida por humanos reales, y solo las personas m√°s cr√©dulos asumen autom√°ticamente que todos los dem√°s son honestos e imparciales. Los cient√≠ficos de verdad no suelen ser tan ingenuos, pero por alguna raz√≥n al mundo le gusta fingir que lo somos, y los libros de texto que solemos escribir parecen reforzar ese estereotipo.


<p style="text-align:right;">
<a href="#id-01">Volver</a>
</p>

---

## Resumen
 
En realidad, este cap√≠tulo no est√° destinado a proporcionar una discusi√≥n exhaustiva de los m√©todos de investigaci√≥n psicol√≥gica: requerir√≠a otro volumen tan largo como este para hacer justicia al tema. Sin embargo, en la vida real, las estad√≠sticas y el dise√±o de estudios est√°n estrechamente entrelazados, por lo que es muy √∫til discutir algunos de los temas clave. En este cap√≠tulo, he analizado brevemente los siguientes temas:
 
- Introducci√≥n a la medici√≥n psicol√≥gica (Secci√≥n 2.1). ¬øQu√© significa operacionalizar un constructo te√≥rico? ¬øQu√© significa tener variables y tomar medidas?
 
- Escalas de medida y tipos de variables (Secci√≥n 2.2). Recuerde que aqu√≠ hay dos distinciones diferentes: existe la diferencia entre datos discretos y continuos, y existe la diferencia entre los cuatro tipos de escala diferentes (nominal, ordinal, intervalo y relaci√≥n).
 
- Fiabilidad de una medici√≥n (Secci√≥n 2.3). Si mido lo "mismo" dos veces, ¬ødeber√≠a esperar ver el mismo resultado? Solo si mi medida es confiable. Pero, ¬øqu√© significa hablar de hacer ‚Äúlo mismo‚Äù? Bueno, por eso tenemos diferentes tipos de confiabilidad. Aseg√∫rese de recordar cu√°les son.
 
- Terminolog√≠a: predictores y resultados (Secci√≥n 2.4). ¬øQu√© papel juegan las variables en un an√°lisis? ¬øPuede recordar la diferencia entre predictores y resultados? ¬øVariables dependientes e independientes? Etc.
 
- Dise√±os de investigaci√≥n experimentales y no experimentales (Secci√≥n 2.5). ¬øQu√© hace que un experimento sea un experimento? ¬øEs una bonita bata blanca de laboratorio o tiene algo que ver con el control del investigador sobre las variables?
 
Validez y sus amenazas (Secci√≥n 2.6). ¬øTu estudio mide lo que quieres que mida? ¬øC√≥mo pueden salir mal las cosas? ¬øY es mi imaginaci√≥n, o es una lista muy larga de posibles formas en las que las cosas pueden salir mal?
 
Todo esto deber√≠a aclararle que el dise√±o del estudio es una parte fundamental de la metodolog√≠a de investigaci√≥n. Constru√≠ este cap√≠tulo a partir del peque√±o libro cl√°sico de Campbell y Stanley (1963), pero, por supuesto, hay una gran cantidad de libros de texto sobre dise√±o de investigaci√≥n. Dedique unos minutos a su motor de b√∫squeda favorito y encontrar√° decenas.



<p style="text-align:right;">
<a href="#id-01">Volver</a>
</p>


---

<p style="text-align:right;font-size:80%;">
Escrito por Navarro, Danielle; traducido por Garc√≠a-Mend√≠vil, Helio A.
</p>